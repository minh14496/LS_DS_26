{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 2, Module 3*\n",
    "\n",
    "---\n",
    "<p style=\"padding: 10px; border: 2px solid red;\">\n",
    "    <b>Before you start:</b> Today is the day you should submit the dataset for your Unit 2 Build Week project. You can review the guidelines and make your submission in the Build Week course for your cohort on Canvas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/main/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "    !pip install pandas-profiling==2.*\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Project: Hyperparameter Tuning\n",
    "\n",
    "This sprint, the module projects will focus on creating and improving a model for the Tanazania Water Pump dataset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
    "\n",
    "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
    "\n",
    "## Directions\n",
    "\n",
    "The tasks for this project are as follows:\n",
    "\n",
    "- **Task 1:** Use `wrangle` function to import training and test data.\n",
    "- **Task 2:** Split training data into feature matrix `X` and target vector `y`.\n",
    "- **Task 3:** Establish the baseline accuracy score for your dataset.\n",
    "- **Task 4:** Build `clf_dt`.\n",
    "- **Task 5:** Build `clf_rf`.\n",
    "- **Task 6:** Evaluate classifiers using k-fold cross-validation.\n",
    "- **Task 7:** Tune hyperparameters for best performing classifier.\n",
    "- **Task 8:** Print out best score and params for model.\n",
    "- **Task 9:** Create `submission.csv` and upload to Kaggle.\n",
    "\n",
    "You should limit yourself to the following libraries for this project:\n",
    "\n",
    "- `category_encoders`\n",
    "- `matplotlib`\n",
    "- `pandas`\n",
    "- `pandas-profiling`\n",
    "- `sklearn`\n",
    "\n",
    "# I. Wrangle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(fm_path, tv_path=None):\n",
    "    if tv_path:\n",
    "        df = pd.merge(pd.read_csv(fm_path, \n",
    "                                  na_values=[0, -2.000000e-08]),\n",
    "                      pd.read_csv(tv_path)).set_index('id')\n",
    "    else:\n",
    "        df = pd.read_csv(fm_path, \n",
    "                         na_values=[0, -2.000000e-08],\n",
    "                         index_col='id')\n",
    "\n",
    "    # Drop constant columns\n",
    "    df.drop(columns=['recorded_by'], inplace=True)\n",
    "\n",
    "    # Drop HCCCs\n",
    "    cutoff = 100\n",
    "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
    "                 if df[col].nunique() > cutoff]\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    # Drop duplicate columns\n",
    "    dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
    "                 if df.head(15).T.duplicated()[col]]\n",
    "    df.drop(columns=dupe_cols, inplace=True)     \n",
    "    # Payment vs payment_type\n",
    "    df = df.drop(columns='payment')\n",
    "    # Waterpoint_type_group vs waterpoint_type\n",
    "    df = df.drop(columns='waterpoint_type_group')\n",
    "    # water_quality vs quality_group\n",
    "    df = df.drop(columns='quality_group')\n",
    "    # Source vs source_type\n",
    "    df = df.drop(columns='source')\n",
    "    # Extraction_type_class vs extraction_type_class\n",
    "    df = df.drop(columns='extraction_type')\n",
    "\n",
    "    # Drop the col with highest proportion of null values\n",
    "    df = df.drop(columns='num_private')       \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1:** Using the above `wrangle` function to read `train_features.csv` and `train_labels.csv` into the DataFrame `df`, and `test_features.csv` into the DataFrame `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle('train_features.csv','train_labels.csv')\n",
    "X_test = wrangle('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Split Data\n",
    "\n",
    "**Task 2:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`.\n",
    "\n",
    "**Note:** You won't need to do a train-test split because you'll use cross-validation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='status_group')\n",
    "y = df['status_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Establish Baseline\n",
    "\n",
    "**Task 3:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline Accuracy Score: 0.5430899510092763\n"
     ]
    }
   ],
   "source": [
    "baseline_acc = y.value_counts(normalize=True).max()\n",
    "print('Baseline Accuracy Score:', baseline_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Build Models\n",
    "\n",
    "**Task 4:** Build a `Pipeline` named `clf_dt`. Your `Pipeline` should include:\n",
    "\n",
    "- an `OrdinalEncoder` transformer for categorical features.\n",
    "- a `SimpleImputer` transformer fot missing values.\n",
    "- a `DecisionTreeClassifier` Predictor.\n",
    "\n",
    "**Note:** Do not train `clf_dt`. You'll do that in a subsequent task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    DecisionTreeClassifier(random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5:** Build a `Pipeline` named `clf_rf`. Your `Pipeline` should include:\n",
    "\n",
    "- an `OrdinalEncoder` transformer for categorical features.\n",
    "- a `SimpleImputer` transformer fot missing values.\n",
    "- a `RandomForestClassifier` predictor.\n",
    "\n",
    "**Note:** Do not train `clf_rf`. You'll do that in a subsequent task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier(random_state=42, \n",
    "                            n_jobs=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Check Metrics\n",
    "\n",
    "**Task 6:** Evaluate the performance of both of your classifiers using k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_dt = cross_val_score(clf_dt, X, y, cv=5, n_jobs=-1)\n",
    "cv_scores_rf = cross_val_score(clf_rf, X, y, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CV scores DecisionTreeClassifier\n[0.75816498 0.74671717 0.75193603 0.75673401 0.74678003]\nMean CV accuracy score: 0.7520664441082827\nSTD CV accuracy score: 0.004807415029655781\n"
     ]
    }
   ],
   "source": [
    "print('CV scores DecisionTreeClassifier')\n",
    "print(cv_scores_dt)\n",
    "print('Mean CV accuracy score:', cv_scores_dt.mean())\n",
    "print('STD CV accuracy score:', cv_scores_dt.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CV score RandomForestClassifier\n[0.80765993 0.80252525 0.80488215 0.8006734  0.80175099]\nMean CV accuracy score: 0.8034983459762483\nSTD CV accuracy score: 0.002498568132101792\n"
     ]
    }
   ],
   "source": [
    "print('CV score RandomForestClassifier')\n",
    "print(cv_scores_rf)\n",
    "print('Mean CV accuracy score:', cv_scores_rf.mean())\n",
    "print('STD CV accuracy score:', cv_scores_rf.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Tune Model\n",
    "\n",
    "**Task 7:** Choose the best performing of your two models and tune its hyperparameters using a `RandomizedSearchCV` named `model`. Make sure that you include cross-validation and that `n_iter` is set to at least `25`.\n",
    "\n",
    "**Note:** If you're not sure which hyperparameters to tune, check the notes from today's guided project and the `sklearn` documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([100., 300., 500., 700.])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "np.linspace(100, 700, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_n_estimators = [int(x) for x in np.linspace(100, 700, 4)]\n",
    "rf_min_samples_split = [int(x) for x in np.linspace(6, 12, 7)]\n",
    "rf_max_features = ['auto', 'sqrt', 'log2']\n",
    "rf_max_depth = [int(x) for x in np.linspace(10, 50, 5)]\n",
    "rf_criterion = ['gini', 'entropy']\n",
    "\n",
    "rf_param = {'randomforestclassifier__n_estimators': rf_n_estimators,\n",
    "            'randomforestclassifier__min_samples_split': rf_min_samples_split,\n",
    "            'randomforestclassifier__max_features': rf_max_features,\n",
    "            'randomforestclassifier__max_depth': rf_max_depth,\n",
    "            'randomforestclassifier__criterion': rf_criterion\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    }
   ],
   "source": [
    "model = RandomizedSearchCV(\n",
    "    estimator=clf_rf, \n",
    "    param_distributions=rf_param,\n",
    "    n_iter=25,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=10\n",
    ")\n",
    "model.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8:** Print out the best score and best params for `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best score for `model`: 0.811343581449651\nBest params for `model`: {'randomforestclassifier__n_estimators': 700, 'randomforestclassifier__min_samples_split': 8, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__max_depth': 30, 'randomforestclassifier__criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "best_score = model.best_score_\n",
    "best_params = model.best_params_\n",
    "\n",
    "print('Best score for `model`:', best_score)\n",
    "print('Best params for `model`:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.811343581449651"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'randomforestclassifier__n_estimators': 700,\n",
       " 'randomforestclassifier__min_samples_split': 8,\n",
       " 'randomforestclassifier__max_features': 'auto',\n",
       " 'randomforestclassifier__max_depth': 30,\n",
       " 'randomforestclassifier__criterion': 'entropy'}"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    " model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9508984538236523"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "test = pd.read_csv('submission_04_13_rf.csv')\n",
    "accuracy_score(test['status_group'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communicate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 9:** Create a DataFrame `submission` whose index is the same as `X_test` and that has one column `'status_group'` with your predictions. Next, save this DataFrame as a CSV file and upload your submissions to our competition site. \n",
    "\n",
    "**Note:** Check the `sample_submission.csv` file on the competition website to make sure your submissions follows the same formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'status_group':y_pred}, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_04_13_rf_3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd015d389823c4ee7e97cbfb3f1e7dc865da6c441c23c0fbc20b562c3f629bc50b4",
   "display_name": "Python 3.9.2 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}